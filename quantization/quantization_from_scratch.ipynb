{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization from scratch\n",
    " - Absmax quantization\n",
    " - Zeropoint quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports\n",
    "import torch\n",
    "from torch import tensor\n",
    "from typing import Optional, Union\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 128, 256)\n"
     ]
    }
   ],
   "source": [
    "# create a random tensor\n",
    "B, M, P = 4, 128, 256\n",
    "weight_tensor = np.random.uniform(-50, 150, (B, M, P))\n",
    "print(weight_tensor.shape)\n",
    "\n",
    "weight_tensor[0, 0, 0] = weight_tensor.max() + 1\n",
    "weight_tensor[0, 0, 1] = weight_tensor.min() - 1\n",
    "weight_tensor[0, 0, 2] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asymmetric_quantization_tensor(tensor: Union[torch.tensor, np.ndarray], bits: int):\n",
    "    \"\"\"\n",
    "    Quantize the input tensor/array by using assymetric uniform quantization:\n",
    "        Also known as zeropoint quantization.\n",
    "    \"\"\"\n",
    "    # find the quantization range and constant\n",
    "    alpha = np.max(tensor)\n",
    "    beta = np.min(tensor)\n",
    "\n",
    "    # quantization constant\n",
    "    scale = (2 ** bits - 1) / (alpha - beta)\n",
    "    zeropoint = -1 * np.round(beta * scale)\n",
    "    lower_bound, upper_bound = 0, 2 ** bits - 1\n",
    "    \n",
    "    tensor_q = np.clip(np.round((tensor * scale) + zeropoint), lower_bound, upper_bound).astype(np.int32)\n",
    "\n",
    "    return tensor_q, scale, zeropoint\n",
    "\n",
    "\n",
    "def symmetric_quantization_tensor(tensor: Union[torch.tensor, np.ndarray], bits: int):\n",
    "    \"\"\"\n",
    "    Quantizer the input tensor/array by using symmetric uniform quantization\n",
    "        also known as absmax quantization\n",
    "    \"\"\"\n",
    "\n",
    "    # find the quantization range and constant\n",
    "    # alpha = np.min(tensor)\n",
    "    beta = np.max(tensor)\n",
    "\n",
    "    # quantization constant\n",
    "    scale = (2 ** (bits - 1) - 1)/ beta \n",
    "    lower_bound, upper_bound = - 2 ** (bits - 1) + 1, 2 ** (bits -1) - 1\n",
    "\n",
    "    tensor_q = np.clip(np.round(tensor * scale), lower_bound, upper_bound).astype(np.int32)\n",
    "\n",
    "    return tensor_q, scale\n",
    "\n",
    "\n",
    "def asymmetric_dequantize(tensor: Union[tensor, np.ndarray], scale: float, zeropoint: float):\n",
    "    \"\"\"\n",
    "    Dequantize asymmetric quantization using scale and input tensor\n",
    "    \"\"\"\n",
    "\n",
    "    return (tensor - zeropoint) / scale \n",
    "\n",
    "\n",
    "def symmetric_dequantize(tensor: Union[tensor, np.ndarray], scale: float) -> Union[tensor, np.ndarray]:\n",
    "    \"\"\" \n",
    "    Dequantize the symmetric quantization operation\n",
    "    \"\"\"\n",
    "\n",
    "    return tensor / scale \n",
    "\n",
    "\n",
    "def quantization_error(tensor_deq: Union[tensor, np.ndarray], tensor: Union[tensor, np.ndarray]) -> float:\n",
    "    \"\"\" \n",
    "    MSE of the quantization after dequantizing\n",
    "    \"\"\"\n",
    "    return np.mean((tensor - tensor_deq) ** 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original :\n",
      "[[[151.   -51.     0.   ... 133.34 140.58 108.55]\n",
      "  [100.7   27.4  139.06 ... 130.54 121.36  91.81]\n",
      "  [ 63.11 112.89  19.36 ...  64.66  -0.9  131.01]\n",
      "  ...\n",
      "  [139.87  19.23  45.87 ... 144.32 111.11  27.78]\n",
      "  [-46.54  26.34 -11.64 ...  38.97  17.3  -37.19]\n",
      "  [ 53.47  20.1   48.86 ...   6.05 -34.25  87.98]]\n",
      "\n",
      " [[ 44.63   8.84 148.58 ... -32.08  69.96  31.05]\n",
      "  [ 48.8   46.9  142.94 ...  86.29  10.   -42.49]\n",
      "  [ 69.18 113.08  97.8  ...  74.43  69.12   7.23]\n",
      "  ...\n",
      "  [ 37.45 124.55 131.54 ...  44.76 113.78  10.45]\n",
      "  [145.13  97.41  78.14 ...  32.84 119.57  98.94]\n",
      "  [-19.12 109.69  77.26 ...  -8.9   45.56  11.11]]\n",
      "\n",
      " [[126.7   26.34  73.78 ...  85.76  -8.23 118.15]\n",
      "  [ 13.95 148.42  67.7  ... -10.4   10.31  99.4 ]\n",
      "  [ 53.88  -9.08   7.43 ...  29.64 -39.71  54.11]\n",
      "  ...\n",
      "  [112.28 -36.95  15.41 ... 122.28   1.97  36.65]\n",
      "  [-41.3   16.26  72.81 ... -15.14  52.82 108.25]\n",
      "  [148.41  84.35  75.77 ... -21.78 -34.7   45.33]]\n",
      "\n",
      " [[-40.31  -1.23  90.2  ... 135.9   27.24 -28.49]\n",
      "  [-25.47  88.04 -13.12 ...  17.77  -0.54   2.34]\n",
      "  [  3.83  21.45 -18.28 ...  -6.74 123.32 -36.56]\n",
      "  ...\n",
      "  [ 73.39 -46.32 -26.49 ... -27.13 148.57  17.51]\n",
      "  [ 41.53 129.83 147.65 ... 122.15  17.16  68.69]\n",
      "  [ 86.73  72.7  -33.73 ... 148.82  19.33   1.31]]]\n",
      "\n",
      "Assymetric scale: 1.262, Zeropoint: 64.0\n",
      "[[[255   0  64 ... 232 241 201]\n",
      "  [191  99 240 ... 229 217 180]\n",
      "  [144 207  88 ... 146  63 229]\n",
      "  ...\n",
      "  [241  88 122 ... 246 204  99]\n",
      "  [  5  97  49 ... 113  86  17]\n",
      "  [132  89 126 ...  72  21 175]]\n",
      "\n",
      " [[120  75 252 ...  24 152 103]\n",
      "  [126 123 244 ... 173  77  10]\n",
      "  [151 207 187 ... 158 151  73]\n",
      "  ...\n",
      "  [111 221 230 ... 121 208  77]\n",
      "  [247 187 163 ... 105 215 189]\n",
      "  [ 40 202 162 ...  53 122  78]]\n",
      "\n",
      " [[224  97 157 ... 172  54 213]\n",
      "  [ 82 251 149 ...  51  77 189]\n",
      "  [132  53  73 ... 101  14 132]\n",
      "  ...\n",
      "  [206  17  83 ... 218  66 110]\n",
      "  [ 12  85 156 ...  45 131 201]\n",
      "  [251 170 160 ...  37  20 121]]\n",
      "\n",
      " [[ 13  62 178 ... 236  98  28]\n",
      "  [ 32 175  47 ...  86  63  67]\n",
      "  [ 69  91  41 ...  55 220  18]\n",
      "  ...\n",
      "  [157   6  31 ...  30 252  86]\n",
      "  [116 228 250 ... 218  86 151]\n",
      "  [173 156  21 ... 252  88  66]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Asymmetric Quantization\n",
    "asym_quantized_weight, asym_scale, asym_zeropoint = asymmetric_quantization_tensor(weight_tensor, 8)\n",
    "print(f'Original :')\n",
    "print(np.round(weight_tensor, 2))\n",
    "print(\"\")\n",
    "print(f'Assymetric scale: {np.round(asym_scale, 3)}, Zeropoint: {asym_zeropoint}')\n",
    "print(asym_quantized_weight)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original :\n",
      "[[[151.   -51.     0.   ... 133.34 140.58 108.55]\n",
      "  [100.7   27.4  139.06 ... 130.54 121.36  91.81]\n",
      "  [ 63.11 112.89  19.36 ...  64.66  -0.9  131.01]\n",
      "  ...\n",
      "  [139.87  19.23  45.87 ... 144.32 111.11  27.78]\n",
      "  [-46.54  26.34 -11.64 ...  38.97  17.3  -37.19]\n",
      "  [ 53.47  20.1   48.86 ...   6.05 -34.25  87.98]]\n",
      "\n",
      " [[ 44.63   8.84 148.58 ... -32.08  69.96  31.05]\n",
      "  [ 48.8   46.9  142.94 ...  86.29  10.   -42.49]\n",
      "  [ 69.18 113.08  97.8  ...  74.43  69.12   7.23]\n",
      "  ...\n",
      "  [ 37.45 124.55 131.54 ...  44.76 113.78  10.45]\n",
      "  [145.13  97.41  78.14 ...  32.84 119.57  98.94]\n",
      "  [-19.12 109.69  77.26 ...  -8.9   45.56  11.11]]\n",
      "\n",
      " [[126.7   26.34  73.78 ...  85.76  -8.23 118.15]\n",
      "  [ 13.95 148.42  67.7  ... -10.4   10.31  99.4 ]\n",
      "  [ 53.88  -9.08   7.43 ...  29.64 -39.71  54.11]\n",
      "  ...\n",
      "  [112.28 -36.95  15.41 ... 122.28   1.97  36.65]\n",
      "  [-41.3   16.26  72.81 ... -15.14  52.82 108.25]\n",
      "  [148.41  84.35  75.77 ... -21.78 -34.7   45.33]]\n",
      "\n",
      " [[-40.31  -1.23  90.2  ... 135.9   27.24 -28.49]\n",
      "  [-25.47  88.04 -13.12 ...  17.77  -0.54   2.34]\n",
      "  [  3.83  21.45 -18.28 ...  -6.74 123.32 -36.56]\n",
      "  ...\n",
      "  [ 73.39 -46.32 -26.49 ... -27.13 148.57  17.51]\n",
      "  [ 41.53 129.83 147.65 ... 122.15  17.16  68.69]\n",
      "  [ 86.73  72.7  -33.73 ... 148.82  19.33   1.31]]]\n",
      "\n",
      "Symmetric scale: 0.841\n",
      "[[[127 -43   0 ... 112 118  91]\n",
      "  [ 85  23 117 ... 110 102  77]\n",
      "  [ 53  95  16 ...  54  -1 110]\n",
      "  ...\n",
      "  [118  16  39 ... 121  93  23]\n",
      "  [-39  22 -10 ...  33  15 -31]\n",
      "  [ 45  17  41 ...   5 -29  74]]\n",
      "\n",
      " [[ 38   7 125 ... -27  59  26]\n",
      "  [ 41  39 120 ...  73   8 -36]\n",
      "  [ 58  95  82 ...  63  58   6]\n",
      "  ...\n",
      "  [ 31 105 111 ...  38  96   9]\n",
      "  [122  82  66 ...  28 101  83]\n",
      "  [-16  92  65 ...  -7  38   9]]\n",
      "\n",
      " [[107  22  62 ...  72  -7  99]\n",
      "  [ 12 125  57 ...  -9   9  84]\n",
      "  [ 45  -8   6 ...  25 -33  46]\n",
      "  ...\n",
      "  [ 94 -31  13 ... 103   2  31]\n",
      "  [-35  14  61 ... -13  44  91]\n",
      "  [125  71  64 ... -18 -29  38]]\n",
      "\n",
      " [[-34  -1  76 ... 114  23 -24]\n",
      "  [-21  74 -11 ...  15   0   2]\n",
      "  [  3  18 -15 ...  -6 104 -31]\n",
      "  ...\n",
      "  [ 62 -39 -22 ... -23 125  15]\n",
      "  [ 35 109 124 ... 103  14  58]\n",
      "  [ 73  61 -28 ... 125  16   1]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Symmetric quantization\n",
    "sym_quantized_weight, sym_scale = symmetric_quantization_tensor(weight_tensor, 8)\n",
    "print(f\"Original :\")\n",
    "print(np.round(weight_tensor, 2))\n",
    "print(\"\")\n",
    "print(f\"Symmetric scale: {np.round(sym_scale, 3)}\")\n",
    "print(sym_quantized_weight)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asymmetric Error: 1685.414\n",
      "Symmetric Error: 0.116\n"
     ]
    }
   ],
   "source": [
    "## Quantization errors\n",
    "print(f'Asymmetric Error: {np.round(quantization_error(asymmetric_dequantize(asym_quantized_weight, asym_scale, asym_zeropoint), weight_tensor), 3)}')\n",
    "\n",
    "print(f'Symmetric Error: {np.round(quantization_error(symmetric_dequantize(sym_quantized_weight, sym_scale), weight_tensor), 3)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
