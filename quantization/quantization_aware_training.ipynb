{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization Aware Training\n",
    " -  adding dummy modules that quantize/ dequantize the weights & activations\n",
    " -  doing this while training, makes the model to learn the quantization patterns\n",
    " -  This leads to improved inference accuracy.\n",
    "\n",
    " **This is used in modern LLM quantization / finetuning (e.g. QLoRA.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "_ = torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1037,), (0.3081))])\n",
    "mnist_train = MNIST(root=\"./data/\", train=True, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=10, shuffle=True)\n",
    "\n",
    "mnist_test = MNIST(root='./data/', train=False, download=True, transform=transform)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=10, shuffle=False)\n",
    "\n",
    "# get gpu\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the quantization aware trainer\n",
    "import torch.ao.quantization\n",
    "\n",
    "\n",
    "class SimpleNetwork(nn.Module):\n",
    "    def __init__(self, hidden_1=128, hidden_2=128, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.quant = torch.ao.quantization.QuantStub()\n",
    "        self.linear_1 = nn.Linear(28 * 28, hidden_1)\n",
    "        self.linear_2 = nn.Linear(hidden_1, hidden_2)\n",
    "        self.linear_3 = nn.Linear(hidden_2, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = img.view(-1, 28 * 28)\n",
    "        x = self.quant(x)\n",
    "        x = self.relu(self.linear_1(x))\n",
    "        x = self.relu(self.linear_2(x))\n",
    "        x = self.linear_3(x)\n",
    "        x = self.dequant(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "model = SimpleNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleNetwork(\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (linear_1): Linear(\n",
       "    in_features=784, out_features=128, bias=True\n",
       "    (weight_fake_quant): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (linear_2): Linear(\n",
       "    in_features=128, out_features=128, bias=True\n",
       "    (weight_fake_quant): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (linear_3): Linear(\n",
       "    in_features=128, out_features=10, bias=True\n",
       "    (weight_fake_quant): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.qconfig = torch.ao.quantization.default_qconfig\n",
    "model.train()\n",
    "\n",
    "model_quantized = torch.ao.quantization.prepare_qat(model)\n",
    "model_quantized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable Parameters (K): 118.282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|█████████▉| 5999/6000 [00:41<00:00, 143.91it/s, loss=0.252]\n",
      "Epoch 2: 100%|█████████▉| 5999/6000 [00:31<00:00, 190.64it/s, loss=0.107]\n",
      "Epoch 3: 100%|█████████▉| 5999/6000 [00:31<00:00, 191.48it/s, loss=0.0737]\n",
      "Epoch 4: 100%|█████████▉| 5999/6000 [00:31<00:00, 193.20it/s, loss=0.0557]\n",
      "Epoch 5: 100%|█████████▉| 5999/6000 [00:32<00:00, 187.36it/s, loss=0.0444]\n"
     ]
    }
   ],
   "source": [
    "def train(train_loader, model, epochs=5, steps_per_epoch=None):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "    global_step = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        loss_sum = 0\n",
    "        step = 0\n",
    "\n",
    "        data_iterator = tqdm(train_loader, desc=f'Epoch {epoch + 1}')\n",
    "        if steps_per_epoch is None:\n",
    "            steps_per_epoch = data_iterator.total\n",
    "\n",
    "        for data in data_iterator:\n",
    "            step += 1\n",
    "            global_step += 1\n",
    "            x, y = data\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass\n",
    "            logits = model(x)\n",
    "            # loss computation\n",
    "            loss = loss_fn(logits, y)\n",
    "            loss_sum += loss.item()\n",
    "\n",
    "            avg_loss = loss_sum / step\n",
    "            data_iterator.set_postfix({'loss': avg_loss})\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if step == steps_per_epoch:\n",
    "                # stopping the iterator\n",
    "                break\n",
    "    \n",
    "    return model\n",
    "\n",
    "def print_model_size(model):\n",
    "    torch.save(model.state_dict(), \"tmp.pth\")\n",
    "    print(f'Size (KB): {os.path.getsize(\"tmp.pth\") / 1e3}')\n",
    "\n",
    "\n",
    "def print_trainable_parameters(model):\n",
    "    trainable_parameters = sum([param.numel() for param in model.parameters() if param.requires_grad])\n",
    "    print(f'Trainable Parameters (K): {trainable_parameters / 1e3}')\n",
    "\n",
    "\n",
    "MODEL_DIR = './models'\n",
    "MODEL_FILENAME = f'{MODEL_DIR}/simplenn_qat.pth'\n",
    "\n",
    "if os.path.exists(MODEL_FILENAME):\n",
    "    model.load_state_dict(torch.load(MODEL_FILENAME))\n",
    "    print(f\"Found model at {MODEL_FILENAME}: Model loaded.\")\n",
    "else:\n",
    "    if not os.path.exists(MODEL_DIR):\n",
    "        os.makedirs(MODEL_DIR)\n",
    "    \n",
    "    print_trainable_parameters(model)\n",
    "    train(train_loader, model_quantized, epochs=5)\n",
    "    torch.save(model_quantized.state_dict(), MODEL_FILENAME)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model: nn.Module, device):\n",
    "    hits = 0\n",
    "    total = 0\n",
    "    # accuracy = hits / total\n",
    "\n",
    "    # set the model device\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader, desc=\"Testing\"):\n",
    "            img, label = data\n",
    "            img, label = img.to(device), label.to(device)\n",
    "            output = model(img)\n",
    "            for idx, o in enumerate(output):\n",
    "                if torch.argmax(o) == label[idx]:\n",
    "                    hits += 1\n",
    "                \n",
    "                total += 1\n",
    "    \n",
    "    print(f'Accuracy: {(hits / total)}')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 1000/1000 [00:01<00:00, 504.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test(model_quantized, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model quantization statistics: \n",
      "SimpleNetwork(\n",
      "  (quant): QuantStub(\n",
      "    (activation_post_process): MinMaxObserver(min_val=-0.33657902479171753, max_val=2.909120559692383)\n",
      "  )\n",
      "  (linear_1): Linear(\n",
      "    in_features=784, out_features=128, bias=True\n",
      "    (weight_fake_quant): MinMaxObserver(min_val=-0.42874079942703247, max_val=0.28564441204071045)\n",
      "    (activation_post_process): MinMaxObserver(min_val=-33.25809860229492, max_val=25.94108009338379)\n",
      "  )\n",
      "  (linear_2): Linear(\n",
      "    in_features=128, out_features=128, bias=True\n",
      "    (weight_fake_quant): MinMaxObserver(min_val=-0.37882840633392334, max_val=0.3766877055168152)\n",
      "    (activation_post_process): MinMaxObserver(min_val=-26.20763397216797, max_val=21.723499298095703)\n",
      "  )\n",
      "  (linear_3): Linear(\n",
      "    in_features=128, out_features=10, bias=True\n",
      "    (weight_fake_quant): MinMaxObserver(min_val=-0.37869828939437866, max_val=0.21585747599601746)\n",
      "    (activation_post_process): MinMaxObserver(min_val=-45.703155517578125, max_val=28.475431442260742)\n",
      "  )\n",
      "  (relu): ReLU()\n",
      "  (dequant): DeQuantStub()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(f'Model quantization statistics: ')\n",
    "print(model_quantized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Didn't find engine for operation quantized::linear_prepack NoQEngine",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m model_quantized\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# model_quantized.load_state_dict(model_trained.state_dict())\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m model_quantized \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mao\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_quantized\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/master/lib/python3.10/site-packages/torch/ao/quantization/quantize.py:553\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(module, mapping, inplace, remove_qconfig, is_reference, convert_custom_config_dict)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inplace:\n\u001b[1;32m    552\u001b[0m     module \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(module)\n\u001b[0;32m--> 553\u001b[0m \u001b[43m_convert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_reference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_reference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_custom_config_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_custom_config_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remove_qconfig:\n\u001b[1;32m    557\u001b[0m     _remove_qconfig(module)\n",
      "File \u001b[0;32m~/miniconda3/envs/master/lib/python3.10/site-packages/torch/ao/quantization/quantize.py:593\u001b[0m, in \u001b[0;36m_convert\u001b[0;34m(module, mapping, inplace, is_reference, convert_custom_config_dict)\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mod, _FusedModule) \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    590\u001b[0m        type_before_parametrizations(mod) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m custom_module_class_mapping:\n\u001b[1;32m    591\u001b[0m         _convert(mod, mapping, \u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# inplace\u001b[39;00m\n\u001b[1;32m    592\u001b[0m                  is_reference, convert_custom_config_dict)\n\u001b[0;32m--> 593\u001b[0m     reassign[name] \u001b[38;5;241m=\u001b[39m \u001b[43mswap_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_module_class_mapping\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m reassign\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    596\u001b[0m     module\u001b[38;5;241m.\u001b[39m_modules[key] \u001b[38;5;241m=\u001b[39m value\n",
      "File \u001b[0;32m~/miniconda3/envs/master/lib/python3.10/site-packages/torch/ao/quantization/quantize.py:626\u001b[0m, in \u001b[0;36mswap_module\u001b[0;34m(mod, mapping, custom_module_class_mapping)\u001b[0m\n\u001b[1;32m    624\u001b[0m         new_mod \u001b[38;5;241m=\u001b[39m qmod\u001b[38;5;241m.\u001b[39mfrom_float(mod, weight_qparams)\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 626\u001b[0m         new_mod \u001b[38;5;241m=\u001b[39m \u001b[43mqmod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_float\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    627\u001b[0m     swapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m swapped:\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;66;03m# Preserve module's pre forward hooks. They'll be called on quantized input\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/master/lib/python3.10/site-packages/torch/ao/nn/quantized/modules/linear.py:277\u001b[0m, in \u001b[0;36mLinear.from_float\u001b[0;34m(cls, mod)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mqint8, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeight observer must have dtype torch.qint8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    276\u001b[0m qweight \u001b[38;5;241m=\u001b[39m _quantize_weight(mod\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mfloat(), weight_post_process)\n\u001b[0;32m--> 277\u001b[0m qlinear \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m              \u001b[49m\u001b[43mmod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m              \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m qlinear\u001b[38;5;241m.\u001b[39mset_weight_bias(qweight, mod\u001b[38;5;241m.\u001b[39mbias)\n\u001b[1;32m    281\u001b[0m qlinear\u001b[38;5;241m.\u001b[39mscale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(act_scale)\n",
      "File \u001b[0;32m~/miniconda3/envs/master/lib/python3.10/site-packages/torch/ao/nn/quantized/modules/linear.py:151\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[0;34m(self, in_features, out_features, bias_, dtype)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnsupported dtype specified for quantized Linear!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 151\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_packed_params \u001b[38;5;241m=\u001b[39m \u001b[43mLinearPackedParams\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_packed_params\u001b[38;5;241m.\u001b[39mset_weight_bias(qweight, bias)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/master/lib/python3.10/site-packages/torch/ao/nn/quantized/modules/linear.py:27\u001b[0m, in \u001b[0;36mLinearPackedParams.__init__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat16:\n\u001b[1;32m     26\u001b[0m     wq \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_weight_bias\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/master/lib/python3.10/site-packages/torch/ao/nn/quantized/modules/linear.py:32\u001b[0m, in \u001b[0;36mLinearPackedParams.set_weight_bias\u001b[0;34m(self, weight, bias)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mexport\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_weight_bias\u001b[39m(\u001b[38;5;28mself\u001b[39m, weight: torch\u001b[38;5;241m.\u001b[39mTensor, bias: Optional[torch\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mqint8:\n\u001b[0;32m---> 32\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_packed_params \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantized\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear_prepack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat16:\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_packed_params \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mquantized\u001b[38;5;241m.\u001b[39mlinear_prepack_fp16(weight, bias)\n",
      "File \u001b[0;32m~/miniconda3/envs/master/lib/python3.10/site-packages/torch/_ops.py:755\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    751\u001b[0m     \u001b[38;5;66;03m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;66;03m# is still callable from JIT\u001b[39;00m\n\u001b[1;32m    753\u001b[0m     \u001b[38;5;66;03m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    754\u001b[0m     \u001b[38;5;66;03m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Didn't find engine for operation quantized::linear_prepack NoQEngine"
     ]
    }
   ],
   "source": [
    "model_quantized.eval()\n",
    "# model_quantized.load_state_dict(model_trained.state_dict())\n",
    "\n",
    "model_quantized = torch.ao.quantization.convert(model_quantized)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
