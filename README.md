## Notebooks to Fine-Tune LLMs on Instruction dataset

The recent developments in the field if NLP can be attributed to LLMS.
LLMs coined Large Language Models are models with Billions of parameters trained on massive data from the internet.
Although these models show execptional knowledge and various emergent properties due to their scale, they are not aligned for human conversations.
To align LLMs to Human preferences we fine-tune them on guess what , 'Human preferences' !!
Various techniques are applied to make them respond well to human instructions, techniques like RLHF, SFT and DPO are popular.

This repo contains notebooks to finetune an LLM on publicly available preference datasets.
